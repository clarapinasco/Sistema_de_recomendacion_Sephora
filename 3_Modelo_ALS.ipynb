{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_21952\\99614358.py:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  re1=pd.read_csv('data/reviews_0-250.csv')\n",
            "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_21952\\99614358.py:4: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  re4=pd.read_csv('data/reviews_750-1250.csv')\n",
            "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_21952\\99614358.py:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  re5=pd.read_csv('data/reviews_1250-end.csv')\n"
          ]
        }
      ],
      "source": [
        "re1=pd.read_csv('data/reviews_0-250.csv')\n",
        "re2=pd.read_csv('data/reviews_250-500.csv')\n",
        "re3=pd.read_csv('data/reviews_500-750.csv')\n",
        "re4=pd.read_csv('data/reviews_750-1250.csv')\n",
        "re5=pd.read_csv('data/reviews_1250-end.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.concat([re1, re2, re3, re4, re5], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1094411, 19)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "578653"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.author_id.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "author_counts = df['author_id'].value_counts()\n",
        "\n",
        "# Filtrar los author_id que se repiten al menos 3 veces\n",
        "author_to_keep = author_counts[author_counts >= 5].index\n",
        "\n",
        "# Actualizar el DataFrame original para conservar solo los author_id que se repiten al menos 3 veces\n",
        "df = df[df['author_id'].isin(author_to_keep)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bv5794T45Mo-"
      },
      "outputs": [],
      "source": [
        "df = df[['author_id', 'rating', 'product_id']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(291493, 3)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['author_id'] = pd.factorize(df['author_id'])[0] + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>product_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>P420652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>P420652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>P420652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>P420652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>P420652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     author_id  rating product_id\n",
              "29           1       4    P420652\n",
              "86           2       5    P420652\n",
              "115          3       3    P420652\n",
              "192          4       1    P420652\n",
              "194          5       4    P420652"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRMCbGy_7a29",
        "outputId": "6cb0773b-acf0-43eb-b15d-a2e3549ff8ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "author_id      int64\n",
              "rating         int64\n",
              "product_id    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ed8cQg3T7DKH"
      },
      "outputs": [],
      "source": [
        "df['author_id'] = df['author_id'].astype(str)\n",
        "\n",
        "# Filter out rows where author_id starts with 'order'\n",
        "df = df[~df['author_id'].str.startswith(('order'))]\n",
        "df['product_id'] = df['product_id'].apply(lambda x: x[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0Hyp9Dx35oSi"
      },
      "outputs": [],
      "source": [
        "\n",
        "df['author_id'] = df['author_id'].astype('int64')\n",
        "df['product_id'] = df['product_id'].astype('int64')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZsC5FDl5VZU",
        "outputId": "1bec5d21-8587-40d3-87cc-d4f6771aba75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "author_id     int64\n",
              "rating        int64\n",
              "product_id    int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"data/df_als.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3pNddAYxO38",
        "outputId": "d1c86010-15a7-4246-df5d-2ed5cf84feca"
      },
      "outputs": [],
      "source": [
        "#!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "o5Zf7K7Xxb_F"
      },
      "outputs": [
        {
          "ename": "PySparkRuntimeError",
          "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[36], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      5\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\n\u001b[1;32m----> 6\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRecommendations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\marti\\OneDrive\\Documentos\\UCEMA\\7\\IA\\Sistema_de_recomendacion_Sephora\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
            "File \u001b[1;32mc:\\Users\\marti\\OneDrive\\Documentos\\UCEMA\\7\\IA\\Sistema_de_recomendacion_Sephora\\.venv\\Lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
            "File \u001b[1;32mc:\\Users\\marti\\OneDrive\\Documentos\\UCEMA\\7\\IA\\Sistema_de_recomendacion_Sephora\\.venv\\Lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\marti\\OneDrive\\Documentos\\UCEMA\\7\\IA\\Sistema_de_recomendacion_Sephora\\.venv\\Lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
            "File \u001b[1;32mc:\\Users\\marti\\OneDrive\\Documentos\\UCEMA\\7\\IA\\Sistema_de_recomendacion_Sephora\\.venv\\Lib\\site-packages\\pyspark\\java_gateway.py:107\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[0;32m    108\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[0;32m    113\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
            "\u001b[1;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import col, explode\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext\n",
        "spark = SparkSession.builder.appName('Recommendations').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yBffoRzxfw5",
        "outputId": "b8a40aa7-6a08-438c-b0b9-581a0baca43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The ratings dataframe is  99.56% empty.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_ratings = df[\"rating\"].count()\n",
        "num_users = df[\"author_id\"].nunique()\n",
        "num_movies = df[\"product_id\"].nunique()\n",
        "\n",
        "denominator = num_users * num_movies\n",
        "\n",
        "sparsity = (1.0 - (num_ratings * 1.0) / denominator) * 100\n",
        "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
            "  check_blas_config()\n"
          ]
        }
      ],
      "source": [
        "from implicit.als import AlternatingLeastSquares\n",
        "model = AlternatingLeastSquares(factors=190, regularization=0.01, iterations=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nicolas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: You are using pip version 22.0.4; however, version 24.1.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Nicolas\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext\n",
        "# sc.setCheckpointDir('checkpoint')\n",
        "spark = SparkSession.builder.appName('Recommendations').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the required functions\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_spark = spark.createDataFrame(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pyspark.ml.recommendation.ALS"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create test and train set\n",
        "(train, test) = df_spark.randomSplit([0.8, 0.2], seed = 1234)\n",
        "\n",
        "# Create ALS model\n",
        "als = ALS(rank=150, regParam=0.01, userCol=\"author_id\", itemCol=\"product_id\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
        "# Confirm that a model called \"als\" was created\n",
        "type(als)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Entrenar el modelo ALS\n",
        "model = als.fit(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar el modelo\n",
        "model.save(\"modelo_als\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<class 'pyspark.ml.recommendation.ALSModel'>\n",
        "**Best Model**\n",
        "  Rank: 150\n",
        "  MaxIter: 10\n",
        "  RegParam: 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root-mean-square error = 0.9732130069092246\n"
          ]
        }
      ],
      "source": [
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root-mean-square error = {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------------+\n",
            "|author_id|     recommendations|\n",
            "+---------+--------------------+\n",
            "|        1|[{478030, 4.99902...|\n",
            "|       12|[{420652, 4.99998...|\n",
            "|       13|[{469088, 5.00474...|\n",
            "|       22|[{422905, 5.11993...|\n",
            "|       26|[{420652, 4.99070...|\n",
            "|       27|[{427406, 5.24030...|\n",
            "|       28|[{469088, 5.80673...|\n",
            "|       31|[{173726, 5.44013...|\n",
            "|       34|[{407444, 4.99992...|\n",
            "|       44|[{302103, 5.36987...|\n",
            "+---------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nrecommendations = model.recommendForAllUsers(10)\n",
        "nrecommendations.limit(10).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+---------+\n",
            "|author_id|product_id|   rating|\n",
            "+---------+----------+---------+\n",
            "|        1|    478030|4.9990263|\n",
            "|        1|    471086|  4.99266|\n",
            "|        1|    464288|  4.99266|\n",
            "|        1|    427406| 4.698785|\n",
            "|        1|    454102|4.4097824|\n",
            "|        1|    455364| 4.375922|\n",
            "|        1|    173726| 4.348395|\n",
            "|        1|    433887|4.3283653|\n",
            "|        1|    422905|4.3254585|\n",
            "|        1|    302103|4.3204165|\n",
            "+---------+----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "# Explode the recommendations column\n",
        "nrecommendations = nrecommendations.withColumn(\"rec_exp\", explode(\"recommendations\"))\n",
        "\n",
        "# Select the relevant columns\n",
        "nrecommendations = nrecommendations.select('author_id', col(\"rec_exp.product_id\"), col(\"rec_exp.rating\"))\n",
        "\n",
        "# Show the first 10 rows\n",
        "nrecommendations.limit(10).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, substring\n",
        "product= spark.read.csv(\"data/product_info.csv\",header=True)\n",
        "product = product.withColumn('product_id', substring(col('product_id'), 2, 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---------+---------+--------------------+--------+-----------------+-----------+------+-------+---------------+--------------+---------------+--------------------+--------------------+---------+---------------+--------------+---------------+---+-----------+------------+-----------------+--------------------+----------------+--------------------+-----------------+-----------+---------------+---------------+\n",
            "|product_id|author_id|   rating|        product_name|brand_id|       brand_name|loves_count|rating|reviews|           size|variation_type|variation_value|      variation_desc|         ingredients|price_usd|value_price_usd|sale_price_usd|limited_edition|new|online_only|out_of_stock|sephora_exclusive|          highlights|primary_category|  secondary_category|tertiary_category|child_count|child_max_price|child_min_price|\n",
            "+----------+---------+---------+--------------------+--------+-----------------+-----------+------+-------+---------------+--------------+---------------+--------------------+--------------------+---------+---------------+--------------+---------------+---+-----------+------------+-----------------+--------------------+----------------+--------------------+-----------------+-----------+---------------+---------------+\n",
            "|    302103|       44|5.3698745|Sugar Advanced Li...|    4348|            fresh|     125611|4.2837|   2957| .15 oz / 4.3 g|         Color|    Translucent|                NULL|['Cera Alba (Bees...|       28|           NULL|          NULL|              0|  0|          0|           0|                0|['Hyaluronic Acid...|        Skincare|Lip Balms & Treat...|             NULL|          0|           NULL|           NULL|\n",
            "|    448715|       44|5.1171217|     Balancing Toner|    6302|Dr. Barbara Sturm|       4371|4.4828|     29|5.07 oz/ 150 mL|          Size|5.07 oz/ 150 mL|                NULL|['Water (Aqua), L...|       75|           NULL|          NULL|              0|  0|          0|           0|                0|['Hyaluronic Acid...|        Skincare|           Cleansers|           Toners|          0|           NULL|           NULL|\n",
            "|    420652|       44| 5.000054|Lip Sleeping Mask...|    6125|          LANEIGE|    1081315|4.3508|  16118|   0.7 oz/ 20 g|         Color|       Original|                NULL|['Diisostearyl Ma...|       24|           NULL|          NULL|              0|  0|          0|           0|                1|['allure 2019 Bes...|        Skincare|Lip Balms & Treat...|             NULL|          3|             24|             24|\n",
            "|    430337|       44| 4.999857|C-Rush Vitamin C ...|    5674|     OLEHENRIKSEN|     105730|4.3404|   2961|  1.7 oz/ 50 mL|          Size|  1.7 oz/ 50 mL|                NULL|['Sources of vita...|       51|           NULL|          NULL|              0|  0|          0|           0|                1|['Vitamin C', 'Go...|        Skincare|        Moisturizers|     Moisturizers|          0|           NULL|           NULL|\n",
            "|    472311|       44|4.9938965|Mini Total Cleans...|    6352|       Fenty Skin|       9677|3.7727|     22| 1.52 oz/ 45 mL|          Size| 1.52 oz/ 45 mL|                NULL|['Aqua/Water/Eau,...|       15|           NULL|          NULL|              0|  0|          1|           0|                1|['Vegan', 'Good f...|        Skincare|           Mini Size|             NULL|          0|           NULL|           NULL|\n",
            "|    421243|       44|4.6482773|Sugar Hydrating L...|    4348|            fresh|     132861|4.1991|   2200|    0.21 oz/ 6g|         Color|     Watermelon|a sheer juicy wat...|['Isononyl Isonon...|       19|           NULL|          NULL|              0|  0|          0|           0|                0|['Clean at Sephor...|        Skincare|Lip Balms & Treat...|             NULL|          2|             19|             19|\n",
            "|    397624|       44|4.6334286|Dermask Micro Jet...|    6014|        Dr. Jart+|      35931|4.4472|    322|         1 Mask|          Type|           NULL|                NULL|['Glycerin, Niaci...|        9|           NULL|          NULL|              0|  0|          0|           0|                0|                NULL|        Skincare|               Masks|      Sheet Masks|          0|           NULL|           NULL|\n",
            "|    447790|       44| 4.561522|Anti-Pollution Drops|    6302|Dr. Barbara Sturm|       3528|3.6327|     49|    1 oz/ 30 mL|          Size|    1 oz/ 30 mL|                NULL|['Water, Betaine,...|      150|           NULL|          NULL|              0|  0|          0|           0|                0|['Good for: Dark ...|        Skincare|          Treatments|      Face Serums|          0|           NULL|           NULL|\n",
            "|    470227|       44| 4.543972|Vitamin C Triple ...|    4164|            Murad|       7452|4.7306|    360|  2.7 oz/ 80 mL|          Size|  2.7 oz/ 80 mL|                NULL|['Glycerin, Silic...|       85|           NULL|          NULL|              0|  0|          0|           0|                0|['Best for Oily, ...|        Skincare|          Treatments|     Facial Peels|          0|           NULL|           NULL|\n",
            "|    439061|       44|4.5387015|Glow2OH Dark Spot...|    5674|     OLEHENRIKSEN|     182201|4.1922|   2955| 6.5 oz/ 190 mL|          Size| 6.5 oz/ 190 mL|                NULL|['Water, Glycolic...|       35|           NULL|          NULL|              0|  0|          0|           0|                1|['Vegan', 'Good f...|        Skincare|           Cleansers|           Toners|          1|             19|             19|\n",
            "+----------+---------+---------+--------------------+--------+-----------------+-----------+------+-------+---------------+--------------+---------------+--------------------+--------------------+---------+---------------+--------------+---------------+---+-----------+------------+-----------------+--------------------+----------------+--------------------+-----------------+-----------+---------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nrecommendations.join(product, on='product_id').filter('author_id=44').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+------+----------+----------+--------------------+--------+--------------+-----------+------+-------+--------------+--------------+---------------+--------------+--------------------+---------+---------------+--------------+---------------+---+-----------+------------+-----------------+--------------------+----------------+--------------------+--------------------+-----------+---------------+---------------+\n",
            "|author_id|rating|product_id|product_id|        product_name|brand_id|    brand_name|loves_count|rating|reviews|          size|variation_type|variation_value|variation_desc|         ingredients|price_usd|value_price_usd|sale_price_usd|limited_edition|new|online_only|out_of_stock|sephora_exclusive|          highlights|primary_category|  secondary_category|   tertiary_category|child_count|child_max_price|child_min_price|\n",
            "+---------+------+----------+----------+--------------------+--------+--------------+-----------+------+-------+--------------+--------------+---------------+--------------+--------------------+---------+---------------+--------------+---------------+---+-----------+------------+-----------------+--------------------+----------------+--------------------+--------------------+-----------+---------------+---------------+\n",
            "|       44|     5|    420652|    420652|Lip Sleeping Mask...|    6125|       LANEIGE|    1081315|4.3508|  16118|  0.7 oz/ 20 g|         Color|       Original|          NULL|['Diisostearyl Ma...|       24|           NULL|          NULL|              0|  0|          0|           0|                1|['allure 2019 Bes...|        Skincare|Lip Balms & Treat...|                NULL|          3|             24|             24|\n",
            "|       44|     5|    430337|    430337|C-Rush Vitamin C ...|    5674|  OLEHENRIKSEN|     105730|4.3404|   2961| 1.7 oz/ 50 mL|          Size|  1.7 oz/ 50 mL|          NULL|['Sources of vita...|       51|           NULL|          NULL|              0|  0|          0|           0|                1|['Vitamin C', 'Go...|        Skincare|        Moisturizers|        Moisturizers|          0|           NULL|           NULL|\n",
            "|       44|     5|    469088|    469088|Fulvic Acid Brigh...|    6285|The INKEY List|      38263|4.4203|    345|  5 oz/ 150 mL|          Size|   5 oz/ 150 mL|          NULL|['Water (Aqua/Eau...|    11.99|           NULL|          NULL|              0|  0|          0|           0|                1|['Good for: Dulln...|        Skincare|           Cleansers|Face Wash & Clean...|          1|           5.99|           5.99|\n",
            "|       44|     5|    478029|    478029|Mini Fulvic Acid ...|    6285|The INKEY List|      18399|4.4203|    345| 1.7 oz/ 50 mL|          Size|  1.7 oz/ 50 mL|          NULL|['Water (Aqua/Eau...|     5.99|           NULL|          NULL|              0|  0|          0|           0|                1|['Good for: Dark ...|        Skincare|           Cleansers|Face Wash & Clean...|          0|           NULL|           NULL|\n",
            "|       44|     5|    472311|    472311|Mini Total Cleans...|    6352|    Fenty Skin|       9677|3.7727|     22|1.52 oz/ 45 mL|          Size| 1.52 oz/ 45 mL|          NULL|['Aqua/Water/Eau,...|       15|           NULL|          NULL|              0|  0|          1|           0|                1|['Vegan', 'Good f...|        Skincare|           Mini Size|                NULL|          0|           NULL|           NULL|\n",
            "+---------+------+----------+----------+--------------------+--------+--------------+-----------+------+-------+--------------+--------------+---------------+--------------+--------------------+---------+---------------+--------------+---------------+---+-----------+------------+-----------------+--------------------+----------------+--------------------+--------------------+-----------+---------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Joining the DataFrames on 'product_id'\n",
        "joined_df = df_spark.join(product, df_spark['product_id'] == product['product_id'])\n",
        "\n",
        "filtered_df = joined_df.filter(col('author_id') == 44)\n",
        "filtered_df.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
